{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ee8cda4",
   "metadata": {},
   "source": [
    "# Automatic Labeling for Coastline Detection\n",
    "\n",
    "This notebook demonstrates how to automatically classify pixels between water and mainland in PNG images using K-Means clustering and an autoencoder for semi-supervised learning. This approach avoids manual labeling of the dataset.\n",
    "\n",
    "## Steps\n",
    "1. Preprocess Images\n",
    "2. Apply K-Means Clustering\n",
    "3. Post-Process the Clustering Results\n",
    "4. Use Autoencoder for Semi-Supervised Classification\n",
    "\n",
    "## Preprocessing Images\n",
    "We will load the images, resize them if necessary, and normalize the pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f93b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, GlobalAveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, cohen_kappa_score, matthews_corrcoef\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Set system encoding to UTF-8 (solve a windows issue with charmap undefiend)\n",
    "import sys\n",
    "sys.stdin.reconfigure(encoding='utf-8')\n",
    "#sys.stdout.reconfigure(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "448f8452",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define function to load and preprocess images\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    return image\n",
    "\n",
    "\n",
    "# Function to verify and clean images\n",
    "def verify_images(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                img = Image.open(file_path)\n",
    "                img.verify()  # Verify that it is an image\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print(f\"Deleting corrupted image: {file_path}\")\n",
    "                os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28252e9",
   "metadata": {},
   "source": [
    "# Normalize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the directories\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "start_epoch = 0\n",
    "base_dir = 'classification'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Verify and clean images\n",
    "verify_images(train_dir)\n",
    "verify_images(validation_dir)\n",
    "\n",
    "# Data preprocessing and augmentation by using ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92422c11",
   "metadata": {},
   "source": [
    "## Applying K-Means Clustering\n",
    "We will convert the image into a vector of pixel values and apply the K-Means algorithm to cluster the pixels into two classes: water and mainland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8dbc18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess a sample image for demonstration\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    return image\n",
    "\n",
    "# Apply K-Means to the image\n",
    "def apply_kmeans(image, n_clusters=2):\n",
    "    pixel_values = image.reshape((-1, 3))\n",
    "    pixel_values = np.float32(pixel_values)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(pixel_values)\n",
    "    segmented_image = labels.reshape(image.shape[:2])\n",
    "    return segmented_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662a3875",
   "metadata": {},
   "source": [
    "## Post-Processing\n",
    "After clustering, we apply morphological filters to remove small misclassified regions and smooth the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6397e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-process the segmented image\n",
    "def post_process(segmented_image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    processed_image = cv2.morphologyEx(segmented_image, cv2.MORPH_CLOSE, kernel)\n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2963e6ba",
   "metadata": {},
   "source": [
    "## Example of K-Means Clustering and Post-Processing\n",
    "Load an image, apply K-Means clustering, and then post-process the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your image\n",
    "import random\n",
    "both_dir = os.path.join(train_dir, 'both')\n",
    "image_files = [f for f in os.listdir(both_dir) if os.path.isfile(os.path.join(both_dir, f))]\n",
    "random_image = random.choice(image_files)\n",
    "image_path = os.path.join(both_dir, random_image)\n",
    "\n",
    "image = load_and_preprocess_image(image_path)\n",
    "\n",
    "# Apply K-Means\n",
    "segmented_image = apply_kmeans(image)\n",
    "\n",
    "# Post-Process\n",
    "processed_image = post_process(segmented_image)\n",
    "\n",
    "# Display results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Segmented Image')\n",
    "plt.imshow(processed_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ed088f",
   "metadata": {},
   "source": [
    "## Using Autoencoder for Semi-Supervised Classification\n",
    "Next, we will use an autoencoder to further refine the classification. The autoencoder will be trained on a set of images to learn the features of water and mainland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the autoencoder model\n",
    "input_img = Input(shape=(256, 256, 3))\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Summary of the model\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66083287",
   "metadata": {},
   "source": [
    "## Training the Autoencoder\n",
    "We will train the autoencoder using a set of training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd78ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train and X_test are pre-loaded datasets of images\n",
    "# Example: X_train and X_test could be loaded using a data generator or any other method\n",
    "\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=128, shuffle=True, validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68412328",
   "metadata": {},
   "source": [
    "## Using the Trained Autoencoder for Classification\n",
    "Use the trained autoencoder to classify pixels in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cafb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the decoded images (predictions)\n",
    "decoded_imgs = autoencoder.predict(X_test)\n",
    "\n",
    "# Display some of the original and decoded images\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i])\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18c1666",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook demonstrates how to use K-Means clustering and an autoencoder for automatic classification of pixels between water and mainland. This approach can be extended and refined with more complex models and larger datasets for improved accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
