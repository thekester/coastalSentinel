{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['autolabeler.old.ipynb', 'autolabeler4.ipynb', 'autolabeler4.py', 'autolabelerv2.ipynb', 'autolabelerv3.ipynb', 'autolabelling.py', 'best_classifier_model.keras', 'best_model.keras', 'best_segmentation_model.keras', 'classification', 'classification.ipynb', 'classification.py', 'classification.zip', 'classification2.zip', 'coastlines.json', 'coastline_classifier.h5', 'coastline_classifier.keras', 'coastline_classifier_1.keras', 'coastline_classifier_10.keras', 'coastline_classifier_11.keras', 'coastline_classifier_12.keras', 'coastline_classifier_13.keras', 'coastline_classifier_2.keras', 'coastline_classifier_3.keras', 'coastline_classifier_4.keras', 'coastline_classifier_5.keras', 'coastline_classifier_6.keras', 'coastline_classifier_7.keras', 'coastline_classifier_8.keras', 'coastline_classifier_9.keras', 'coastline_classifier_epoch_10.keras', 'coastline_classifier_epoch_100.keras', 'coastline_classifier_epoch_101.keras', 'coastline_classifier_epoch_102.keras', 'coastline_classifier_epoch_103.keras', 'coastline_classifier_epoch_104.keras', 'coastline_classifier_epoch_105.keras', 'coastline_classifier_epoch_106.keras', 'coastline_classifier_epoch_107.keras', 'coastline_classifier_epoch_108.keras', 'coastline_classifier_epoch_109.keras', 'coastline_classifier_epoch_110.keras', 'coastline_classifier_epoch_111.keras', 'coastline_classifier_epoch_112.keras', 'coastline_classifier_epoch_113.keras', 'coastline_classifier_epoch_114.keras', 'coastline_classifier_epoch_115.keras', 'coastline_classifier_epoch_116.keras', 'coastline_classifier_epoch_117.keras', 'coastline_classifier_epoch_118.keras', 'coastline_classifier_epoch_119.keras', 'coastline_classifier_epoch_120.keras', 'coastline_classifier_epoch_121.keras', 'coastline_classifier_epoch_122.keras', 'coastline_classifier_epoch_20.keras', 'coastline_classifier_epoch_93.keras', 'coastline_classifier_epoch_94.keras', 'coastline_classifier_epoch_95.keras', 'coastline_classifier_epoch_96.keras', 'coastline_classifier_epoch_97.keras', 'coastline_classifier_epoch_98.keras', 'coastline_classifier_epoch_99.keras', 'confusion_matrix.png', 'confusion_matrix_0_30_epochs.png', 'confusion_matrix_10_40_epochs.png', 'confusion_matrix_20_50_epochs.png', 'confusion_matrix_56_86_epochs.png', 'data1984part2.png', 'data1985part1.png', 'data1985part2.png', 'data1985part3.png', 'data2003part1.png', 'data2003part2.png', 'data2006part3.png', 'data2010part1.png', 'data2010part2.png', 'data2010part3.png', 'data2014part1.png', 'data2014part2.png', 'data2014part2juillet.png', 'data2014part3.png', 'data2015part1.png', 'data2015part3.png', 'data2017part1.png', 'data2017part2.png', 'data2018part3.png', 'data2019part3.png', 'data2020part1.png', 'data2020part2.png', 'data2020part3.png', 'data2021avrilpart3.png', 'data2021marspart3.png', 'data2024part2.png', 'dataset', 'dataset_label', 'distance.py', 'dounambay', 'dounambay.ipynb', 'hawai', 'logs', 'metrics_0_30_epochs.json', 'runpy.py', 'swed_transform.ipynb', 'test', 'test.ipynb', 'test.jpg', 'test_labeled_images.pkl', 'training_history.png', 'training_history_0_30_epochs.png', 'training_history_10_40_epochs.png', 'training_history_20_50_epochs.png', 'training_history_56_86_epochs.png', 'training_metrics.json', 'train_labeled_images.pkl', 'tryhard.py', 'updated_autolabeler.ipynb', 'use_autolabeler.ipynb']\n",
      "['dounambay/coastline/dounambay2005_annotated_coastline.png', 'dounambay/coastline/dounambayapril2013_annotated_coastline.png', 'dounambay/coastline/dounambayapril2019_annotated_coastline.png', 'dounambay/coastline/dounambayapril2024_annotated_coastline.png', 'dounambay/coastline/dounambayjuly2011_annotated_coastline.png', 'dounambay/coastline/dounambaymay2019_annotated_coastline.png', 'dounambay/coastline/dounambaymay2021_annotated_coastline.png'] coastlines.json\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from shapely.geometry import LineString, mapping\n",
    "import geojson\n",
    "import os\n",
    "\n",
    "\n",
    "# List of annotated image paths\n",
    "image_paths = [\n",
    "    \"dounambay/annotations/dounambay2005_annotated.png\",\n",
    "    \"dounambay/annotations/dounambayapril2013_annotated.png\",\n",
    "    \"dounambay/annotations/dounambayapril2019_annotated.png\",\n",
    "    \"dounambay/annotations/dounambayapril2024_annotated.png\",\n",
    "    \"dounambay/annotations/dounambayjuly2011_annotated.png\",\n",
    "    \"dounambay/annotations/dounambaymay2019_annotated.png\",\n",
    "    \"dounambay/annotations/dounambaymay2021_annotated.png\",\n",
    "]\n",
    "\n",
    "# Prepare to store GeoJSON features\n",
    "features = []\n",
    "\n",
    "# Process each image\n",
    "for image_path in image_paths:\n",
    "    # Extract the file name without the extension\n",
    "    image_name = os.path.basename(image_path).replace('.png', '')\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Check if the image is loaded correctly\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply threshold to create a binary image\n",
    "    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(binary, 100, 200)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create a black image\n",
    "    coastline_image = np.zeros_like(gray)\n",
    "    \n",
    "    # Draw the contours in white\n",
    "    cv2.drawContours(coastline_image, contours, -1, (255, 255, 255), 1)\n",
    "    \n",
    "    # Save the contour image\n",
    "    coastline_image_path = f\"dounambay/coastline/{image_name}_coastline.png\"\n",
    "    cv2.imwrite(coastline_image_path, coastline_image)\n",
    "    \n",
    "    # Convert the contours to GeoJSON\n",
    "    for contour in contours:\n",
    "        if len(contour) > 1:  # Ensure the contour has more than one point\n",
    "            coordinates = contour[:, 0, :].tolist()\n",
    "            linestring = LineString(coordinates)\n",
    "            feature = {\n",
    "                \"type\": \"Feature\",\n",
    "                \"geometry\": mapping(linestring),\n",
    "                \"properties\": {\n",
    "                    \"image\": image_name  # File name without extension\n",
    "                }\n",
    "            }\n",
    "            features.append(feature)\n",
    "\n",
    "# Create a GeoJSON FeatureCollection\n",
    "geojson_dict = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "\n",
    "# Save the GeoJSON data)\n",
    "print(os.listdir())\n",
    "geojson_file_path = \"coastlines.json\"\n",
    "with open(geojson_file_path, 'w') as f:\n",
    "    geojson.dump(geojson_dict, f)\n",
    "\n",
    "# Display the paths to the saved images and the GeoJSON file\n",
    "coastline_image_paths = [f\"dounambay/coastline/{os.path.basename(image_path).replace('.png', '')}_coastline.png\" for image_path in image_paths]\n",
    "print(coastline_image_paths, geojson_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
