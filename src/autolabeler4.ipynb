{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typer\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Cropping2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "app = typer.Typer()\n",
    "\n",
    "def load_images_from_directory(directory: str, label: int, img_height: int = 150, img_width: int = 150):\n",
    "    images = []\n",
    "    labels = []\n",
    "    filenames = []\n",
    "    for filename in tqdm(os.listdir(directory), desc=f\"Loading {label} images\"):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "            filenames.append(filename)\n",
    "    return np.array(images), np.array(labels), filenames\n",
    "\n",
    "class ImageDisplayCallback(Callback):\n",
    "    def __init__(self, test_data, filenames, manual_label_filenames, manual_label_dir):\n",
    "        self.test_data = test_data\n",
    "        self.filenames = filenames\n",
    "        self.manual_label_filenames = manual_label_filenames\n",
    "        self.manual_label_dir = manual_label_dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        X_test = self.test_data\n",
    "        filenames = self.filenames\n",
    "        indices = np.random.choice(len(X_test), 5, replace=False)\n",
    "        predictions = self.model.predict(X_test)\n",
    "        plt.figure(figsize=(20, 9))  # Increase figure height for better spacing\n",
    "        for i, idx in enumerate(indices):  # Displaying 5 random examples\n",
    "            ax = plt.subplot(3, 5, i + 1)\n",
    "            plt.imshow(X_test[idx])\n",
    "            plt.title(f'Original\\n{filenames[idx]}')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            ax = plt.subplot(3, 5, i + 6)\n",
    "            plt.imshow(np.argmax(predictions[idx], axis=-1), cmap='jet')\n",
    "            plt.title(f'Predicted\\n{filenames[idx]}')\n",
    "            ax.axis('off')\n",
    "\n",
    "            if filenames[idx] in self.manual_label_filenames:\n",
    "                manual_label_path = os.path.join(self.manual_label_dir, filenames[idx])\n",
    "                print('The file is in manual label ')\n",
    "                print(manual_label_path)\n",
    "                manual_label = cv2.imread(manual_label_path)\n",
    "                manual_label = cv2.resize(manual_label, (img_width, img_height))\n",
    "                ax = plt.subplot(3, 5, i + 11)\n",
    "                plt.imshow(manual_label)\n",
    "                plt.title(f'Manual Label\\n{filenames[idx]}')\n",
    "                ax.axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Epoch {epoch + 1}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    y_pred_labels = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred_labels = tf.cast(y_pred_labels, tf.int64)  # Ensure y_pred_labels are int64\n",
    "\n",
    "    print(\"Debugging combined_loss:\")\n",
    "    print(\"y_pred_labels dtype:\", y_pred_labels.dtype)\n",
    "    print(\"y_pred_labels shape:\", y_pred_labels.shape)\n",
    "\n",
    "    for filename in manual_label_filenames:\n",
    "        manual_label_path = os.path.join(manual_label_dir, filename)\n",
    "        manual_image = cv2.imread(manual_label_path)\n",
    "        manual_image = cv2.resize(manual_image, (img_width, img_height))\n",
    "        manual_image = manual_image.astype(np.float32) / 255.0\n",
    "\n",
    "        # Initialize the manual mask with -1 for undefined pixels\n",
    "        manual_mask = np.full((img_height, img_width), -1, dtype=np.int64)\n",
    "        manual_mask[np.all(manual_image == [0, 0, 255], axis=-1)] = 0  # Mainland\n",
    "        manual_mask[np.all(manual_image == [255, 0, 0], axis=-1)] = 1  # Water\n",
    "        manual_mask = tf.convert_to_tensor(manual_mask, dtype=tf.int64)  # Ensure manual_mask is int64\n",
    "\n",
    "        print(\"Before correction:\")\n",
    "        print(\"manual_mask dtype:\", manual_mask.dtype)\n",
    "        print(\"manual_mask shape:\", manual_mask.shape)\n",
    "\n",
    "        # Ensure the shapes are compatible\n",
    "        manual_mask = tf.expand_dims(manual_mask, axis=-1)  # Add channel dimension\n",
    "        manual_mask = tf.image.resize_with_crop_or_pad(manual_mask, y_pred_labels.shape[1], y_pred_labels.shape[2])\n",
    "        manual_mask = tf.squeeze(manual_mask, axis=-1)  # Remove channel dimension\n",
    "\n",
    "        y_pred_labels_squeezed = tf.squeeze(y_pred_labels, axis=0)  # Remove batch dimension\n",
    "\n",
    "        print(\"After correction:\")\n",
    "        print(\"manual_mask shape after resize_with_crop_or_pad and squeeze:\", manual_mask.shape)\n",
    "        print(\"y_pred_labels_squeezed shape after squeeze:\", y_pred_labels_squeezed.shape)\n",
    "\n",
    "        # Add explanation for adding a dimension\n",
    "        print(\"Adding a channel dimension to y_pred_labels_squeezed to match manual_mask dimensions for loss calculation.\")\n",
    "\n",
    "        # Ensure y_pred_labels_squeezed has the right shape for loss calculation\n",
    "        y_pred_labels_squeezed = tf.expand_dims(y_pred_labels_squeezed, axis=-1)  # Add channel dimension\n",
    "\n",
    "        print(\"y_pred_labels_squeezed:\", y_pred_labels_squeezed)\n",
    "\n",
    "        # Ensure that all values in manual_mask are valid indices (0 or 1)\n",
    "        valid_mask = tf.not_equal(manual_mask, -1)\n",
    "        manual_mask = tf.boolean_mask(manual_mask, valid_mask)\n",
    "        y_pred_labels_squeezed = tf.boolean_mask(y_pred_labels_squeezed, valid_mask)\n",
    "        \n",
    "        print(\"manual_mask (after filtering undefined pixels):\", manual_mask)\n",
    "        print(\"manual_mask type:\", manual_mask.dtype)\n",
    "        print(\"y_pred_labels_squeezed (after filtering undefined pixels):\", y_pred_labels_squeezed)\n",
    "        print(\"y_pred_labels_squeezed type:\", y_pred_labels_squeezed.dtype)\n",
    "\n",
    "        # Ensure the types of tensors for loss calculation are consistent\n",
    "        manual_mask = tf.cast(manual_mask, tf.int64)\n",
    "        y_pred_labels_squeezed = tf.cast(y_pred_labels_squeezed, tf.int64)\n",
    "\n",
    "        # Calculate manual_loss\n",
    "        manual_loss = tf.keras.losses.sparse_categorical_crossentropy(manual_mask, y_pred_labels_squeezed)\n",
    "        print(\"manual_loss:\", manual_loss)\n",
    "        print(\"manual_loss type:\", type(manual_loss))\n",
    "\n",
    "        loss += manual_loss\n",
    "    return loss\n",
    "\n",
    "@app.command()\n",
    "def train(\n",
    "    img_height: int = 150,\n",
    "    img_width: int = 150,\n",
    "    batch_size: int = 32,\n",
    "    epochs: int = 20,\n",
    "    base_dir: str = 'classification',\n",
    "    model_path: str = 'best_segmentation_model.keras'\n",
    "):\n",
    "    base_dir = os.path.abspath(base_dir)\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    validation_dir = os.path.join(base_dir, 'validation')\n",
    "    model_path = os.path.abspath(model_path)\n",
    "    manual_label_dir = os.path.join(base_dir, 'manual_label/train/both')\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    train_mainland_dir = os.path.join(train_dir, 'mainland')\n",
    "    train_water_dir = os.path.join(train_dir, 'water')\n",
    "    train_both_dir = os.path.join(train_dir, 'both')\n",
    "\n",
    "    mainland_images, mainland_labels, _ = load_images_from_directory(train_mainland_dir, label=0)\n",
    "    water_images, water_labels, _ = load_images_from_directory(train_water_dir, label=1)\n",
    "    both_images, _, both_filenames = load_images_from_directory(train_both_dir, label=2)\n",
    "\n",
    "    manual_label_filenames = [f for f in os.listdir(manual_label_dir) if os.path.isfile(os.path.join(manual_label_dir, f))]\n",
    "\n",
    "    X = np.concatenate((mainland_images, water_images), axis=0)\n",
    "    y = np.concatenate((mainland_labels, water_labels), axis=0)\n",
    "\n",
    "    X = X.astype(np.float32)\n",
    "    both_images = both_images.astype(np.float32)\n",
    "\n",
    "    X /= 255.0\n",
    "    both_images /= 255.0\n",
    "\n",
    "    def create_pixelwise_labels(images, label):\n",
    "        labels = np.ones((images.shape[0], img_height, img_width), dtype=np.uint8) * label\n",
    "        return labels\n",
    "\n",
    "    mainland_pixelwise_labels = create_pixelwise_labels(mainland_images, 0)\n",
    "    water_pixelwise_labels = create_pixelwise_labels(water_images, 1)\n",
    "\n",
    "    y_pixelwise = np.concatenate((mainland_pixelwise_labels, water_pixelwise_labels), axis=0)\n",
    "\n",
    "    print(\"Unique values in mainland_pixelwise_labels:\", np.unique(mainland_pixelwise_labels))\n",
    "    print(\"Unique values in water_pixelwise_labels:\", np.unique(water_pixelwise_labels))\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y_pixelwise, test_size=0.2, random_state=42)\n",
    "\n",
    "    input_img = Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    print(\"Shape after Conv2D(64):\", x.shape)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    print(\"Shape after MaxPooling2D:\", x.shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    print(\"Shape after Conv2D(32):\", x.shape)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    print(\"Shape after encoding MaxPooling2D:\", encoded.shape)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(encoded)\n",
    "    print(\"Shape after UpSampling2D:\", x.shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    print(\"Shape after Conv2D(32) in decoder:\", x.shape)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    print(\"Shape after UpSampling2D:\", x.shape)\n",
    "    x = Cropping2D(((1, 1), (1, 1)))(x) \n",
    "    print(\"Shape after Cropping2D:\", x.shape)\n",
    "    decoded = Conv2D(2, (3, 3), activation='softmax', padding='same')(x)\n",
    "    print(\"Shape after final Conv2D:\", decoded.shape)\n",
    "\n",
    "    segmentation_model = Model(input_img, decoded)\n",
    "    segmentation_model.compile(optimizer='adam', loss=combined_loss, metrics=['accuracy'])\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        continue_training = typer.prompt(\"A model already exists. Do you want to continue training it? (yes/no): \")\n",
    "        if continue_training.lower() == 'yes':\n",
    "            segmentation_model = load_model(model_path)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(factor=0.2, patience=5),\n",
    "        ModelCheckpoint(model_path, save_best_only=True),\n",
    "        ImageDisplayCallback(both_images, both_filenames, manual_label_filenames, manual_label_dir)\n",
    "    ]\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    history = segmentation_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    segmentation_model.load_weights(model_path)\n",
    "\n",
    "    both_predictions = segmentation_model.predict(both_images)\n",
    "\n",
    "    both_masks = np.argmax(both_predictions, axis=-1)\n",
    "\n",
    "    print(\"Shape of both_images:\", both_images.shape)\n",
    "    print(\"Shape of both_predictions:\", both_predictions.shape)\n",
    "    print(\"Shape of both_masks:\", both_masks.shape)\n",
    "    print(\"Unique values in both_masks:\", np.unique(both_masks))\n",
    "\n",
    "    def visualize_segmentation(images, masks, filenames, manual_label_filenames, manual_label_dir, n=5):\n",
    "        indices = np.random.choice(len(images), n, replace=False)\n",
    "        plt.figure(figsize=(20, 9))\n",
    "        for i, idx in enumerate(indices):\n",
    "            ax = plt.subplot(3, n, i + 1)\n",
    "            plt.imshow(images[idx])\n",
    "            plt.title(f'Original\\n{filenames[idx]}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            ax = plt.subplot(3, n, i + 1 + n)\n",
    "            mask = np.zeros((images[idx].shape[0], images[idx].shape[1], 3), dtype=np.uint8)\n",
    "            for j in range(images[idx].shape[0]):\n",
    "                for k in range(images[idx].shape[1]):\n",
    "                    if masks[idx][j, k] == 0:\n",
    "                        mask[j, k] = [128, 0, 128]  # Mainland in purple\n",
    "                    elif masks[idx][j, k] == 1:\n",
    "                        mask[j, k] = [255, 255, 0]  # Water in yellow\n",
    "            plt.imshow(mask)\n",
    "            plt.title(f'Segmented\\n{filenames[idx]}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            if filenames[idx] in manual_label_filenames:\n",
    "                manual_label_path = os.path.join(manual_label_dir, filenames[idx])\n",
    "                manual_label = cv2.imread(manual_label_path)\n",
    "                manual_label = cv2.resize(manual_label, (img_width, img_height))\n",
    "                manual_label = cv2.cvtColor(manual_label, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "                manual_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "                manual_mask[np.all(manual_label == [0, 0, 255], axis=-1)] = [128, 0, 128]  # Mainland in purple\n",
    "                manual_mask[np.all(manual_label == [255, 0, 0], axis=-1)] = [255, 255, 0]  # Water in yellow\n",
    "                ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
    "                plt.imshow(manual_mask)\n",
    "                plt.title(f'Manual Label\\n{filenames[idx]}')\n",
    "                plt.axis('off')\n",
    "\n",
    "        plt.legend(['Mainland in purple', 'Water in yellow'], loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    visualize_segmentation(both_images, both_masks, both_filenames, manual_label_filenames, manual_label_dir)\n",
    "\n",
    "    def plot_training_history(history):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Loss')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "        plt.legend()\n",
    "        plt.title('Accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    plot_training_history(history)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
