{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: d:\\googlearthdata\\classification\n",
      "Train directory: d:\\googlearthdata\\classification\\train\n",
      "Validation directory: d:\\googlearthdata\\classification\\validation\n",
      "Model path: d:\\googlearthdata\\best_segmentation_model.keras\n",
      "Manual label directory: d:\\googlearthdata\\classification\\manual_label/train/both\n",
      "Starting data loading...\n",
      "Found 1205 images belonging to 3 classes.\n",
      "Found 243 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading 0 images: 100%|██████████| 401/401 [00:13<00:00, 29.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 401 images from d:\\googlearthdata\\classification\\train\\mainland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading 1 images: 100%|██████████| 402/402 [00:11<00:00, 33.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 402 images from d:\\googlearthdata\\classification\\train\\water\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading 2 images: 100%|██████████| 402/402 [00:15<00:00, 26.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 402 images from d:\\googlearthdata\\classification\\train\\both\n",
      "Unique values in mainland_pixelwise_labels: [0.]\n",
      "Unique values in water_pixelwise_labels: [1.]\n",
      "Shape after Conv2D(64): (None, 150, 150, 64)\n",
      "Shape after MaxPooling2D: (None, 75, 75, 64)\n",
      "Shape after Conv2D(32): (None, 75, 75, 32)\n",
      "Shape after encoding MaxPooling2D: (None, 38, 38, 32)\n",
      "Shape after UpSampling2D: (None, 76, 76, 32)\n",
      "Shape after Conv2D(32) in decoder: (None, 76, 76, 32)\n",
      "Shape after UpSampling2D: (None, 152, 152, 32)\n",
      "Shape after Cropping2D: (None, 150, 150, 32)\n",
      "Shape after final Conv2D: (None, 150, 150, 2)\n",
      "Starting training...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'simple_combined_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 378\u001b[0m\n\u001b[0;32m    376\u001b[0m response \u001b[38;5;241m=\u001b[39m get_user_input(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo you want to start training? (yes/no): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 378\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 300\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(img_height, img_width, batch_size, epochs, base_dir, model_path, continue_training)\u001b[0m\n\u001b[0;32m    292\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    293\u001b[0m     EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m    294\u001b[0m     ReduceLROnPlateau(factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),\n\u001b[0;32m    295\u001b[0m     ModelCheckpoint(model_path, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m    296\u001b[0m     ImageDisplayCallback(both_images, both_filenames, manual_label_filenames, manual_label_dir, img_height, img_width)\n\u001b[0;32m    297\u001b[0m ]\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 300\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43msegmentation_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m segmentation_model\u001b[38;5;241m.\u001b[39mload_weights(model_path)\n\u001b[0;32m    310\u001b[0m both_predictions \u001b[38;5;241m=\u001b[39m segmentation_model\u001b[38;5;241m.\u001b[39mpredict(both_images)\n",
      "File \u001b[1;32mc:\\Users\\Avenel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:/Users/Avenel/AppData/Local/Temp/ipykernel_6736/1140193871.py:278\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[1;31mNameError\u001b[0m: name 'simple_combined_loss' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Cropping2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "# Define the weighted cross entropy function\n",
    "def weighted_cross_entropy(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=y_pred.shape[-1])  # Ensure y_true is one-hot encoded\n",
    "        y_true = tf.cast(y_true, tf.float32)  # Convert y_true to float32\n",
    "\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Define the combined loss function\n",
    "def combined_loss(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        # Use the weighted cross entropy loss function\n",
    "        weighted_loss = weighted_cross_entropy(weights)\n",
    "\n",
    "        # Calculate the main loss\n",
    "        main_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "        y_pred_labels = tf.argmax(y_pred, axis=-1)\n",
    "        y_pred_labels = tf.cast(y_pred_labels, tf.float32)  # Ensure y_pred_labels are float32\n",
    "\n",
    "        print(\"Debugging combined_loss:\")\n",
    "        print(\"y_pred_labels dtype:\", y_pred_labels.dtype)\n",
    "        print(\"y_pred_labels shape:\", y_pred_labels.shape)\n",
    "\n",
    "        mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "        for filename in manual_label_filenames:\n",
    "            manual_label_path = os.path.join(manual_label_dir, filename)\n",
    "            manual_image = cv2.imread(manual_label_path)\n",
    "            manual_image = cv2.resize(manual_image, (img_width, img_height))\n",
    "            manual_image = manual_image.astype(np.float32) / 255.0\n",
    "\n",
    "            # Initialize the manual mask with -1 for undefined pixels\n",
    "            manual_mask = np.full((img_height, img_width), -1, dtype=np.float32)\n",
    "            manual_mask[np.all(manual_image == [0, 0, 255], axis=-1)] = 0.0  # Mainland\n",
    "            manual_mask[np.all(manual_image == [255, 0, 0], axis=-1)] = 1.0  # Water\n",
    "            manual_mask = tf.convert_to_tensor(manual_mask, dtype=tf.float32)  # Ensure manual_mask is float32\n",
    "\n",
    "            print(\"Before correction:\")\n",
    "            print(\"manual_mask dtype:\", manual_mask.dtype)\n",
    "            print(\"manual_mask shape:\", manual_mask.shape)\n",
    "\n",
    "            # Ensure the shapes are compatible\n",
    "            manual_mask = tf.expand_dims(manual_mask, axis=0)  # Add batch dimension\n",
    "            manual_mask = tf.expand_dims(manual_mask, axis=-1)  # Add channel dimension\n",
    "            manual_mask = tf.image.resize_with_crop_or_pad(manual_mask, img_height, img_width)\n",
    "\n",
    "            print(\"After correction:\")\n",
    "            print(\"manual_mask shape after resize_with_crop_or_pad:\", manual_mask.shape)\n",
    "\n",
    "            # Ensure that all values in manual_mask are valid indices (0 or 1)\n",
    "            valid_mask = tf.not_equal(manual_mask, -1.0)\n",
    "            valid_mask = tf.squeeze(valid_mask, axis=-1)  # Squeeze the channel dimension\n",
    "            manual_mask_filtered = tf.boolean_mask(manual_mask, valid_mask)\n",
    "            y_pred_labels_filtered = tf.boolean_mask(y_pred_labels, valid_mask)\n",
    "\n",
    "            print(\"manual_mask (after filtering undefined pixels):\", manual_mask_filtered)\n",
    "            print(\"manual_mask type:\", manual_mask_filtered.dtype)\n",
    "            print(\"manual_mask shape:\", manual_mask_filtered.shape)\n",
    "            print(\"y_pred_labels (after filtering undefined pixels):\", y_pred_labels_filtered)\n",
    "            print(\"y_pred_labels type:\", y_pred_labels_filtered.dtype)\n",
    "            print(\"y_pred_labels shape:\", y_pred_labels_filtered.shape)\n",
    "\n",
    "            # Calculate manual_loss using Mean Squared Error\n",
    "            manual_loss = mse_loss_fn(manual_mask_filtered, y_pred_labels_filtered)\n",
    "            print(\"manual_loss:\", manual_loss)\n",
    "            print(\"manual_loss type:\", type(manual_loss))\n",
    "\n",
    "            main_loss += manual_loss\n",
    "\n",
    "        return main_loss + weighted_loss(y_true, y_pred)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Initialize weights outside the loss function\n",
    "weights = K.variable([0.1, 0.9])\n",
    "\n",
    "# Define paths to the directories\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "base_dir = os.path.abspath('classification')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "model_path = os.path.abspath('best_segmentation_model.keras')\n",
    "manual_label_dir = os.path.join(base_dir, 'manual_label/train/both')\n",
    "manual_label_filenames = [f for f in os.listdir(manual_label_dir) if os.path.isfile(os.path.join(manual_label_dir, f))]\n",
    "\n",
    "\n",
    "print(f\"Base directory: {base_dir}\")\n",
    "print(f\"Train directory: {train_dir}\")\n",
    "print(f\"Validation directory: {validation_dir}\")\n",
    "print(f\"Model path: {model_path}\")\n",
    "print(f\"Manual label directory: {manual_label_dir}\")\n",
    "\n",
    "def load_images_from_directory(directory: str, label: int, img_height: int = 150, img_width: int = 150):\n",
    "    images = []\n",
    "    labels = []\n",
    "    filenames = []\n",
    "    for filename in tqdm(os.listdir(directory), desc=f\"Loading {label} images\"):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "            filenames.append(filename)\n",
    "    print(f\"Loaded {len(images)} images from {directory}\")\n",
    "    return np.array(images), np.array(labels), filenames\n",
    "\n",
    "class ImageDisplayCallback(Callback):\n",
    "    def __init__(self, test_data, filenames, manual_label_filenames, manual_label_dir, img_height, img_width):\n",
    "        self.test_data = test_data\n",
    "        self.filenames = filenames\n",
    "        self.manual_label_filenames = manual_label_filenames\n",
    "        self.manual_label_dir = manual_label_dir\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        X_test = self.test_data\n",
    "        filenames = self.filenames\n",
    "        indices = np.random.choice(len(X_test), 5, replace=False)\n",
    "        predictions = self.model.predict(X_test)\n",
    "        plt.figure(figsize=(20, 9))  # Increase figure height for better spacing\n",
    "        for i, idx in enumerate(indices):  # Displaying 5 random examples\n",
    "            ax = plt.subplot(3, 5, i + 1)\n",
    "            plt.imshow(X_test[idx])\n",
    "            plt.title(f'Original\\n{filenames[idx]}')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            ax = plt.subplot(3, 5, i + 6)\n",
    "            plt.imshow(np.argmax(predictions[idx], axis=-1), cmap='jet')\n",
    "            plt.title(f'Predicted\\n{filenames[idx]}')\n",
    "            ax.axis('off')\n",
    "\n",
    "            if filenames[idx] in self.manual_label_filenames:\n",
    "                manual_label_path = os.path.join(self.manual_label_dir, filenames[idx])\n",
    "                manual_label = cv2.imread(manual_label_path)\n",
    "                manual_label = cv2.resize(manual_label, (self.img_width, self.img_height))\n",
    "                ax = plt.subplot(3, 5, i + 11)\n",
    "                plt.imshow(manual_label)\n",
    "                plt.title(f'Manual Label\\n{filenames[idx]}')\n",
    "                ax.axis('off')\n",
    "\n",
    "        plt.suptitle(f'Epoch {epoch + 1}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def get_user_input(prompt, timeout=10, default=\"yes\"):\n",
    "    def user_input_thread(prompt, result):\n",
    "        result.append(input(prompt))\n",
    "\n",
    "    result = []\n",
    "    thread = threading.Thread(target=user_input_thread, args=(prompt, result))\n",
    "    thread.start()\n",
    "    thread.join(timeout)\n",
    "    if not result:\n",
    "        return default\n",
    "    return result[0]\n",
    "\n",
    "def train(img_height: int = 150, img_width: int = 150, batch_size: int = 32, epochs: int = 20, base_dir: str = 'classification', model_path: str = 'best_segmentation_model.keras', continue_training: bool = False):\n",
    "    base_dir = os.path.abspath(base_dir)\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    validation_dir = os.path.join(base_dir, 'validation')\n",
    "    model_path = os.path.abspath(model_path)\n",
    "    manual_label_dir = os.path.join(base_dir, 'manual_label/train/both')\n",
    "\n",
    "    print(\"Starting data loading...\")\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    train_mainland_dir = os.path.join(train_dir, 'mainland')\n",
    "    train_water_dir = os.path.join(train_dir, 'water')\n",
    "    train_both_dir = os.path.join(train_dir, 'both')\n",
    "\n",
    "    mainland_images, mainland_labels, _ = load_images_from_directory(train_mainland_dir, label=0, img_height=img_height, img_width=img_width)\n",
    "    water_images, water_labels, _ = load_images_from_directory(train_water_dir, label=1, img_height=img_height, img_width=img_width)\n",
    "    both_images, _, both_filenames = load_images_from_directory(train_both_dir, label=2, img_height=img_height, img_width=img_width)\n",
    "\n",
    "    manual_label_filenames = [f for f in os.listdir(manual_label_dir) if os.path.isfile(os.path.join(manual_label_dir, f))]\n",
    "\n",
    "    X = np.concatenate((mainland_images, water_images), axis=0)\n",
    "    y = np.concatenate((mainland_labels, water_labels), axis=0)\n",
    "\n",
    "    X = X.astype(np.float32)\n",
    "    both_images = both_images.astype(np.float32)\n",
    "\n",
    "    X /= 255.0\n",
    "    both_images /= 255.0\n",
    "\n",
    "    def create_pixelwise_labels(images, label):\n",
    "        labels = np.ones((images.shape[0], img_height, img_width), dtype=np.float32) * label\n",
    "        return labels\n",
    "\n",
    "    mainland_pixelwise_labels = create_pixelwise_labels(mainland_images, 0.0)\n",
    "    water_pixelwise_labels = create_pixelwise_labels(water_images, 1.0)\n",
    "\n",
    "    y_pixelwise = np.concatenate((mainland_pixelwise_labels, water_pixelwise_labels), axis=0)\n",
    "\n",
    "    print(\"Unique values in mainland_pixelwise_labels:\", np.unique(mainland_pixelwise_labels))\n",
    "    print(\"Unique values in water_pixelwise_labels:\", np.unique(water_pixelwise_labels))\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y_pixelwise, test_size=0.2, random_state=42)\n",
    "\n",
    "    input_img = Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    print(\"Shape after Conv2D(64):\", x.shape)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    print(\"Shape after MaxPooling2D:\", x.shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    print(\"Shape after Conv2D(32):\", x.shape)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    print(\"Shape after encoding MaxPooling2D:\", encoded.shape)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(encoded)\n",
    "    print(\"Shape after UpSampling2D:\", x.shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    print(\"Shape after Conv2D(32) in decoder:\", x.shape)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    print(\"Shape after UpSampling2D:\", x.shape)\n",
    "    x = Cropping2D(((1, 1), (1, 1)))(x) \n",
    "    print(\"Shape after Cropping2D:\", x.shape)\n",
    "    decoded = Conv2D(2, (3, 3), activation='softmax', padding='same')(x)\n",
    "    print(\"Shape after final Conv2D:\", decoded.shape)\n",
    "\n",
    "    segmentation_model = Model(input_img, decoded)\n",
    "    # Rest of your code remains unchanged, except the call to combined_loss\n",
    "    segmentation_model.compile(optimizer='adam', loss=combined_loss(weights), metrics=['accuracy'])\n",
    "    #segmentation_model.compile(optimizer='adam', loss=combined_loss(), metrics=['accuracy'])\n",
    "\n",
    "    # Check if the model already exists and prompt the user\n",
    "    if os.path.exists(model_path):\n",
    "        continue_training = input(\"A model already exists. Do you want to continue training it? (yes/no): \")\n",
    "        if continue_training.lower() == 'yes':\n",
    "            # Load the model with custom loss function, using safe_mode=False to allow lambda deserialization\n",
    "            segmentation_model = load_model(model_path, custom_objects={'loss': combined_loss()}, safe_mode=False)  # Use safe_mode=False\n",
    "        elif continue_training.lower() == 'no':\n",
    "            print(\"Training a new model.\")\n",
    "        else:\n",
    "            print(\"Invalid input. Training a new model.\")\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(factor=0.2, patience=5),\n",
    "        ModelCheckpoint(model_path, save_best_only=True),\n",
    "        ImageDisplayCallback(both_images, both_filenames, manual_label_filenames, manual_label_dir, img_height, img_width)\n",
    "    ]\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    history = segmentation_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    segmentation_model.load_weights(model_path)\n",
    "\n",
    "    both_predictions = segmentation_model.predict(both_images)\n",
    "\n",
    "    both_masks = np.argmax(both_predictions, axis=-1)\n",
    "\n",
    "    print(\"Shape of both_images:\", both_images.shape)\n",
    "    print(\"Shape of both_predictions:\", both_predictions.shape)\n",
    "    print(\"Shape of both_masks:\", both_masks.shape)\n",
    "    print(\"Unique values in both_masks:\", np.unique(both_masks))\n",
    "\n",
    "    def visualize_segmentation(images, masks, filenames, manual_label_filenames, manual_label_dir, n=5):\n",
    "        indices = np.random.choice(len(images), n, replace=False)\n",
    "        plt.figure(figsize=(20, 9))\n",
    "        for i, idx in enumerate(indices):\n",
    "            ax = plt.subplot(3, n, i + 1)\n",
    "            plt.imshow(images[idx])\n",
    "            plt.title(f'Original\\n{filenames[idx]}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            ax = plt.subplot(3, n, i + 1 + n)\n",
    "            mask = np.zeros((images[idx].shape[0], images[idx].shape[1], 3), dtype=np.uint8)\n",
    "            for j in range(images[idx].shape[0]):\n",
    "                for k in range(images[idx].shape[1]):\n",
    "                    if masks[idx][j, k] == 0:\n",
    "                        mask[j, k] = [128, 0, 128]  # Mainland in purple\n",
    "                    elif masks[idx][j, k] == 1:\n",
    "                        mask[j, k] = [255, 255, 0]  # Water in yellow\n",
    "            plt.imshow(mask)\n",
    "            plt.title(f'Segmented\\n{filenames[idx]}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            if filenames[idx] in manual_label_filenames:\n",
    "                manual_label_path = os.path.join(manual_label_dir, filenames[idx])\n",
    "                manual_label = cv2.imread(manual_label_path)\n",
    "                manual_label = cv2.resize(manual_label, (img_width, img_height))\n",
    "                manual_label = cv2.cvtColor(manual_label, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "                manual_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "                manual_mask[np.all(manual_label == [0, 0, 255], axis=-1)] = [128, 0, 128]  # Mainland in purple\n",
    "                manual_mask[np.all(manual_label == [255, 0, 0], axis=-1)] = [255, 255, 0]  # Water in yellow\n",
    "                ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
    "                plt.imshow(manual_mask)\n",
    "                plt.title(f'Manual Label\\n{filenames[idx]}')\n",
    "                plt.axis('off')\n",
    "\n",
    "        plt.legend(['Mainland in purple', 'Water in yellow'], loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    visualize_segmentation(both_images, both_masks, both_filenames, manual_label_filenames, manual_label_dir)\n",
    "\n",
    "    def plot_training_history(history):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Loss')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "        plt.legend()\n",
    "        plt.title('Accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    plot_training_history(history)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    response = get_user_input(\"Do you want to start training? (yes/no): \")\n",
    "    if response.lower() == \"yes\":\n",
    "        train()\n",
    "    else:\n",
    "        print(\"Training aborted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: d:\\googlearthdata\\classification\n",
      "Train directory: d:\\googlearthdata\\classification\\train\n",
      "Validation directory: d:\\googlearthdata\\classification\\validation\n",
      "Model path: d:\\googlearthdata\\best_segmentation_model.keras\n",
      "Manual label directory: d:\\googlearthdata\\classification\\manual_label/train/both\n",
      "Starting data loading...\n",
      "Found 1205 images belonging to 3 classes.\n",
      "Found 243 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading 0 images: 100%|██████████| 401/401 [00:11<00:00, 33.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 401 images from d:\\googlearthdata\\classification\\train\\mainland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading 1 images: 100%|██████████| 402/402 [00:10<00:00, 40.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 402 images from d:\\googlearthdata\\classification\\train\\water\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading 2 images: 100%|██████████| 402/402 [00:11<00:00, 35.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 402 images from d:\\googlearthdata\\classification\\train\\both\n",
      "Unique values in mainland_pixelwise_labels: [0.]\n",
      "Unique values in water_pixelwise_labels: [1.]\n",
      "Shape after Conv2D(64): (None, 150, 150, 64)\n",
      "Shape after MaxPooling2D: (None, 75, 75, 64)\n",
      "Shape after Conv2D(32): (None, 75, 75, 32)\n",
      "Shape after encoding MaxPooling2D: (None, 38, 38, 32)\n",
      "Shape after UpSampling2D: (None, 76, 76, 32)\n",
      "Shape after Conv2D(32) in decoder: (None, 76, 76, 32)\n",
      "Shape after UpSampling2D: (None, 152, 152, 32)\n",
      "Shape after Cropping2D: (None, 150, 150, 32)\n",
      "Shape after final Conv2D: (None, 150, 150, 2)\n",
      "Starting training...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'simple_combined_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 378\u001b[0m\n\u001b[0;32m    376\u001b[0m response \u001b[38;5;241m=\u001b[39m get_user_input(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo you want to start training? (yes/no): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 378\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 300\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(img_height, img_width, batch_size, epochs, base_dir, model_path, continue_training)\u001b[0m\n\u001b[0;32m    292\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    293\u001b[0m     EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m    294\u001b[0m     ReduceLROnPlateau(factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),\n\u001b[0;32m    295\u001b[0m     ModelCheckpoint(model_path, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m    296\u001b[0m     ImageDisplayCallback(both_images, both_filenames, manual_label_filenames, manual_label_dir, img_height, img_width)\n\u001b[0;32m    297\u001b[0m ]\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 300\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43msegmentation_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m segmentation_model\u001b[38;5;241m.\u001b[39mload_weights(model_path)\n\u001b[0;32m    310\u001b[0m both_predictions \u001b[38;5;241m=\u001b[39m segmentation_model\u001b[38;5;241m.\u001b[39mpredict(both_images)\n",
      "File \u001b[1;32mc:\\Users\\Avenel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:/Users/Avenel/AppData/Local/Temp/ipykernel_6736/1140193871.py:278\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[1;31mNameError\u001b[0m: name 'simple_combined_loss' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Cropping2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Suppress TensorFlow logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Define the weighted cross entropy function\n",
    "def weighted_cross_entropy(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=y_pred.shape[-1])  # Ensure y_true is one-hot encoded\n",
    "        y_true = tf.cast(y_true, tf.float32)  # Convert y_true to float32\n",
    "\n",
    "        y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        loss = y_true * tf.math.log(y_pred) * weights\n",
    "        loss = -tf.reduce_sum(loss, -1)\n",
    "        return loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Define the combined loss function\n",
    "def combined_loss(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        # Use the weighted cross entropy loss function\n",
    "        weighted_loss = weighted_cross_entropy(weights)\n",
    "\n",
    "        # Calculate the main loss\n",
    "        main_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "        y_pred_labels = tf.argmax(y_pred, axis=-1)\n",
    "        y_pred_labels = tf.cast(y_pred_labels, tf.float32)  # Ensure y_pred_labels are float32\n",
    "\n",
    "        mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "        for filename in manual_label_filenames:\n",
    "            manual_label_path = os.path.join(manual_label_dir, filename)\n",
    "            manual_image = cv2.imread(manual_label_path)\n",
    "            manual_image = cv2.resize(manual_image, (img_width, img_height))\n",
    "            manual_image = manual_image.astype(np.float32) / 255.0\n",
    "\n",
    "            # Initialize the manual mask with -1 for undefined pixels\n",
    "            manual_mask = np.full((img_height, img_width), -1, dtype=np.float32)\n",
    "            manual_mask[np.all(manual_image == [0, 0, 255], axis=-1)] = 0.0  # Mainland\n",
    "            manual_mask[np.all(manual_image == [255, 0, 0], axis=-1)] = 1.0  # Water\n",
    "            manual_mask = tf.convert_to_tensor(manual_mask, dtype=tf.float32)  # Ensure manual_mask is float32\n",
    "\n",
    "            # Ensure the shapes are compatible\n",
    "            manual_mask = tf.expand_dims(manual_mask, axis=0)  # Add batch dimension\n",
    "            manual_mask = tf.expand_dims(manual_mask, axis=-1)  # Add channel dimension\n",
    "            manual_mask = tf.image.resize_with_crop_or_pad(manual_mask, img_height, img_width)\n",
    "\n",
    "            # Ensure that all values in manual_mask are valid indices (0 or 1)\n",
    "            valid_mask = tf.not_equal(manual_mask, -1.0)\n",
    "            valid_mask = tf.squeeze(valid_mask, axis=-1)  # Squeeze the channel dimension\n",
    "            manual_mask_filtered = tf.boolean_mask(manual_mask, valid_mask)\n",
    "            y_pred_labels_filtered = tf.boolean_mask(y_pred_labels, valid_mask)\n",
    "\n",
    "            # Calculate manual_loss using Mean Squared Error\n",
    "            manual_loss = mse_loss_fn(manual_mask_filtered, y_pred_labels_filtered)\n",
    "\n",
    "            main_loss += manual_loss\n",
    "\n",
    "        return main_loss + weighted_loss(y_true, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Initialize weights outside the loss function\n",
    "weights = K.variable([0.1, 0.9])\n",
    "\n",
    "# Define paths to the directories\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "base_dir = os.path.abspath('classification')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "model_path = os.path.abspath('best_segmentation_model.keras')\n",
    "manual_label_dir = os.path.join(base_dir, 'manual_label/train/both')\n",
    "manual_label_filenames = [f for f in os.listdir(manual_label_dir) if os.path.isfile(os.path.join(manual_label_dir, f))]\n",
    "\n",
    "print(f\"Base directory: {base_dir}\")\n",
    "print(f\"Train directory: {train_dir}\")\n",
    "print(f\"Validation directory: {validation_dir}\")\n",
    "print(f\"Model path: {model_path}\")\n",
    "print(f\"Manual label directory: {manual_label_dir}\")\n",
    "\n",
    "def load_images_from_directory(directory: str, label: int, img_height: int = 150, img_width: int = 150):\n",
    "    images = []\n",
    "    labels = []\n",
    "    filenames = []\n",
    "    for filename in tqdm(os.listdir(directory), desc=f\"Loading {label} images\"):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "            filenames.append(filename)\n",
    "    print(f\"Loaded {len(images)} images from {directory}\")\n",
    "    return np.array(images), np.array(labels), filenames\n",
    "\n",
    "class ImageDisplayCallback(Callback):\n",
    "    def __init__(self, test_data, filenames, manual_label_filenames, manual_label_dir, img_height, img_width):\n",
    "        self.test_data = test_data\n",
    "        self.filenames = filenames\n",
    "        self.manual_label_filenames = manual_label_filenames\n",
    "        self.manual_label_dir = manual_label_dir\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        X_test = self.test_data\n",
    "        filenames = self.filenames\n",
    "        indices = np.random.choice(len(X_test), 5, replace=False)\n",
    "        predictions = self.model.predict(X_test)\n",
    "        plt.figure(figsize=(20, 9))  # Increase figure height for better spacing\n",
    "        for i, idx in enumerate(indices):  # Displaying 5 random examples\n",
    "            ax = plt.subplot(3, 5, i + 1)\n",
    "            plt.imshow(X_test[idx])\n",
    "            plt.title(f'Original\\n{filenames[idx]}')\n",
    "            ax.axis('off')\n",
    "\n",
    "            ax = plt.subplot(3, 5, i + 6)\n",
    "            plt.imshow(np.argmax(predictions[idx], axis=-1), cmap='jet')\n",
    "            plt.title(f'Predicted\\n{filenames[idx]}')\n",
    "            ax.axis('off')\n",
    "\n",
    "            if filenames[idx] in self.manual_label_filenames:\n",
    "                manual_label_path = os.path.join(self.manual_label_dir, filenames[idx])\n",
    "                manual_label = cv2.imread(manual_label_path)\n",
    "                manual_label = cv2.resize(manual_label, (self.img_width, self.img_height))\n",
    "                ax = plt.subplot(3, 5, i + 11)\n",
    "                plt.imshow(manual_label)\n",
    "                plt.title(f'Manual Label\\n{filenames[idx]}')\n",
    "                ax.axis('off')\n",
    "\n",
    "        plt.suptitle(f'Epoch {epoch + 1}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def get_user_input(prompt, timeout=10, default=\"yes\"):\n",
    "    def user_input_thread(prompt, result):\n",
    "        result.append(input(prompt))\n",
    "\n",
    "    result = []\n",
    "    thread = threading.Thread(target=user_input_thread, args=(prompt, result))\n",
    "    thread.start()\n",
    "    thread.join(timeout)\n",
    "    if not result:\n",
    "        return default\n",
    "    return result[0]\n",
    "\n",
    "def train(img_height: int = 150, img_width: int = 150, batch_size: int = 32, epochs: int = 20, base_dir: str = 'classification', model_path: str = 'best_segmentation_model.keras', continue_training: bool = False):\n",
    "    base_dir = os.path.abspath(base_dir)\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    validation_dir = os.path.join(base_dir, 'validation')\n",
    "    model_path = os.path.abspath(model_path)\n",
    "    manual_label_dir = os.path.join(base_dir, 'manual_label/train/both')\n",
    "\n",
    "    print(\"Starting data loading...\")\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    train_mainland_dir = os.path.join(train_dir, 'mainland')\n",
    "    train_water_dir = os.path.join(train_dir, 'water')\n",
    "    train_both_dir = os.path.join(train_dir, 'both')\n",
    "\n",
    "    mainland_images, mainland_labels, _ = load_images_from_directory(train_mainland_dir, label=0, img_height=img_height, img_width=img_width)\n",
    "    water_images, water_labels, _ = load_images_from_directory(train_water_dir, label=1, img_height=img_height, img_width=img_width)\n",
    "    both_images, _, both_filenames = load_images_from_directory(train_both_dir, label=2, img_height=img_height, img_width=img_width)\n",
    "\n",
    "    manual_label_filenames = [f for f in os.listdir(manual_label_dir) if os.path.isfile(os.path.join(manual_label_dir, f))]\n",
    "\n",
    "    X = np.concatenate((mainland_images, water_images), axis=0)\n",
    "    y = np.concatenate((mainland_labels, water_labels), axis=0)\n",
    "\n",
    "    X = X.astype(np.float32)\n",
    "    both_images = both_images.astype(np.float32)\n",
    "\n",
    "    X /= 255.0\n",
    "    both_images /= 255.0\n",
    "\n",
    "    def create_pixelwise_labels(images, label):\n",
    "        labels = np.ones((images.shape[0], img_height, img_width), dtype=np.float32) * label\n",
    "        return labels\n",
    "\n",
    "    mainland_pixelwise_labels = create_pixelwise_labels(mainland_images, 0.0)\n",
    "    water_pixelwise_labels = create_pixelwise_labels(water_images, 1.0)\n",
    "\n",
    "    y_pixelwise = np.concatenate((mainland_pixelwise_labels, water_pixelwise_labels), axis=0)\n",
    "\n",
    "    print(\"Unique values in mainland_pixelwise_labels:\", np.unique(mainland_pixelwise_labels))\n",
    "    print(\"Unique values in water_pixelwise_labels:\", np.unique(water_pixelwise_labels))\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y_pixelwise, test_size=0.2, random_state=42)\n",
    "\n",
    "    input_img = Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(encoded)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Cropping2D(((1, 1), (1, 1)))(x)\n",
    "    decoded = Conv2D(2, (3, 3), activation='softmax', padding='same')(x)\n",
    "\n",
    "    segmentation_model = Model(input_img, decoded)\n",
    "    segmentation_model.compile(optimizer='adam', loss=combined_loss(weights), metrics=['accuracy'])\n",
    "\n",
    "    # Check if the model already exists and prompt the user\n",
    "    if os.path.exists(model_path):\n",
    "        continue_training = input(\"A model already exists. Do you want to continue training it? (yes/no): \")\n",
    "        if continue_training.lower() == 'yes':\n",
    "            # Load the model with custom loss function\n",
    "            segmentation_model = load_model(model_path, custom_objects={'loss': combined_loss(weights)})\n",
    "        elif continue_training.lower() == 'no':\n",
    "            print(\"Training a new model.\")\n",
    "        else:\n",
    "            print(\"Invalid input. Training a new model.\")\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(factor=0.2, patience=5),\n",
    "        ModelCheckpoint(model_path, save_best_only=True),\n",
    "        ImageDisplayCallback(both_images, both_filenames, manual_label_filenames, manual_label_dir, img_height, img_width)\n",
    "    ]\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    history = segmentation_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # Save the trained model\n",
    "    print(\"Saving trained model...\")\n",
    "    segmentation_model.save(model_path)\n",
    "\n",
    "    segmentation_model.load_weights(model_path)\n",
    "\n",
    "    both_predictions = segmentation_model.predict(both_images)\n",
    "\n",
    "    both_masks = np.argmax(both_predictions, axis=-1)\n",
    "\n",
    "    print(\"Shape of both_images:\", both_images.shape)\n",
    "    print(\"Shape of both_predictions:\", both_predictions.shape)\n",
    "    print(\"Shape of both_masks:\", both_masks.shape)\n",
    "    print(\"Unique values in both_masks:\", np.unique(both_masks))\n",
    "\n",
    "    def visualize_segmentation(images, masks, filenames, manual_label_filenames, manual_label_dir, n=5):\n",
    "        indices = np.random.choice(len(images), n, replace=False)\n",
    "        plt.figure(figsize=(20, 9))\n",
    "        for i, idx in enumerate(indices):\n",
    "            ax = plt.subplot(3, n, i + 1)\n",
    "            plt.imshow(images[idx])\n",
    "            plt.title(f'Original\\n{filenames[idx]}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            ax = plt.subplot(3, n, i + 1 + n)\n",
    "            mask = np.zeros((images[idx].shape[0], images[idx].shape[1], 3), dtype=np.uint8)\n",
    "            for j in range(images[idx].shape[0]):\n",
    "                for k in range(images[idx].shape[1]):\n",
    "                    if masks[idx][j, k] == 0:\n",
    "                        mask[j, k] = [128, 0, 128]  # Mainland in purple\n",
    "                    elif masks[idx][j, k] == 1:\n",
    "                        mask[j, k] = [255, 255, 0]  # Water in yellow\n",
    "            plt.imshow(mask)\n",
    "            plt.title(f'Segmented\\n{filenames[idx]}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            if filenames[idx] in manual_label_filenames:\n",
    "                manual_label_path = os.path.join(manual_label_dir, filenames[idx])\n",
    "                manual_label = cv2.imread(manual_label_path)\n",
    "                manual_label = cv2.resize(manual_label, (img_width, img_height))\n",
    "                manual_label = cv2.cvtColor(manual_label, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "                manual_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "                manual_mask[np.all(manual_label == [0, 0, 255], axis=-1)] = [128, 0, 128]  # Mainland in purple\n",
    "                manual_mask[np.all(manual_label == [255, 0, 0], axis=-1)] = [255, 255, 0]  # Water in yellow\n",
    "                ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
    "                plt.imshow(manual_mask)\n",
    "                plt.title(f'Manual Label\\n{filenames[idx]}')\n",
    "                plt.axis('off')\n",
    "\n",
    "        plt.legend(['Mainland in purple', 'Water in yellow'], loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    visualize_segmentation(both_images, both_masks, both_filenames, manual_label_filenames, manual_label_dir)\n",
    "\n",
    "    def plot_training_history(history):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Loss')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "        plt.legend()\n",
    "        plt.title('Accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    plot_training_history(history)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    response = get_user_input(\"Do you want to start training? (yes/no): \")\n",
    "    if response.lower() == \"yes\":\n",
    "        train()\n",
    "    else:\n",
    "        print(\"Training aborted.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
